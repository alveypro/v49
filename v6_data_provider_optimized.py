#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ğŸ”¥ v6.0æ•°æ®æä¾›æ¨¡å— - ä¼˜åŒ–ç‰ˆï¼ˆä½¿ç”¨æœ¬åœ°æ•°æ®åº“ï¼‰
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
é¿å…Tushare APIé™æµï¼Œä½¿ç”¨æœ¬åœ°æ•°æ®åº“è®¡ç®—æ¿å—çƒ­åº¦
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

import sqlite3
import tushare as ts
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import logging
from functools import lru_cache

logger = logging.getLogger(__name__)

TUSHARE_TOKEN = "9ad24a6745c2625e7e2064d03855f5a419efa06c97e5e7df70c64856"
PERMANENT_DB_PATH = "/Users/mac/QLIB/permanent_stock_database.db"


class V6DataProviderOptimized:
    """v6.0æ•°æ®æä¾›è€… - ä¼˜åŒ–ç‰ˆï¼ˆä½¿ç”¨æœ¬åœ°æ•°æ®åº“ï¼‰"""
    
    def __init__(self):
        ts.set_token(TUSHARE_TOKEN)
        self.pro = ts.pro_api(TUSHARE_TOKEN)
        self._sector_cache = {}
        self._money_flow_cache = {}
        self._north_money_cache = {}
        self._industry_performance_cache = None  # å…¨å±€è¡Œä¸šè¡¨ç°ç¼“å­˜
        self._hs_const_stocks = None  # é™†è‚¡é€šæ ‡çš„ç¼“å­˜
        
    def get_stock_sector(self, ts_code: str) -> Dict:
        """
        è·å–è‚¡ç¥¨æ‰€å±æ¿å—/è¡Œä¸šï¼ˆä»æœ¬åœ°æ•°æ®åº“ï¼‰
        
        è¿”å›ï¼š
        {
            'industry': 'ç”µå­',
            'concept': [],  # æ¦‚å¿µæš‚æ—¶ç®€åŒ–
            'area': 'æ·±åœ³'
        }
        """
        try:
            # ä½¿ç”¨ç¼“å­˜
            cache_key = ts_code
            if cache_key in self._sector_cache:
                return self._sector_cache[cache_key]
            
            # ä»æœ¬åœ°æ•°æ®åº“è·å–
            conn = sqlite3.connect(PERMANENT_DB_PATH)
            query = """
                SELECT industry, name
                FROM stock_basic
                WHERE ts_code = ?
            """
            df = pd.read_sql_query(query, conn, params=(ts_code,))
            conn.close()
            
            if len(df) == 0:
                return {'industry': 'å…¶ä»–', 'concept': [], 'area': 'æœªçŸ¥'}
            
            industry = df['industry'].iloc[0] if not pd.isna(df['industry'].iloc[0]) else 'å…¶ä»–'
            
            # ä»è‚¡ç¥¨åç§°æ¨æ–­æ¦‚å¿µï¼ˆç®€åŒ–ç‰ˆï¼‰
            name = df['name'].iloc[0] if 'name' in df.columns else ''
            concepts = []
            hot_keywords = {
                'æ–°èƒ½æº': ['æ–°èƒ½æº', 'é”‚ç”µ', 'å…‰ä¼', 'å‚¨èƒ½'],
                'äººå·¥æ™ºèƒ½': ['AI', 'äººå·¥æ™ºèƒ½', 'å¤§æ¨¡å‹', 'ç®—åŠ›'],
                'èŠ¯ç‰‡': ['èŠ¯ç‰‡', 'åŠå¯¼ä½“', 'é›†æˆç”µè·¯'],
                'ç”Ÿç‰©åŒ»è¯': ['åŒ»è¯', 'ç”Ÿç‰©', 'ç–«è‹—', 'åŒ»ç–—']
            }
            for concept_name, keywords in hot_keywords.items():
                if any(keyword in name or keyword in industry for keyword in keywords):
                    concepts.append(concept_name)
            
            result = {
                'industry': industry,
                'concept': concepts[:3],  # æœ€å¤š3ä¸ªæ¦‚å¿µ
                'area': 'æœªçŸ¥'
            }
            
            # ç¼“å­˜
            self._sector_cache[cache_key] = result
            return result
            
        except Exception as e:
            logger.warning(f"è·å–æ¿å—ä¿¡æ¯å¤±è´¥ {ts_code}: {e}")
            return {'industry': 'å…¶ä»–', 'concept': [], 'area': 'æœªçŸ¥'}
    
    def get_sector_performance(self, industry: str, days: int = 3) -> Dict:
        """
        è·å–æ¿å—è¡¨ç°ï¼ˆä»æœ¬åœ°æ•°æ®åº“è®¡ç®—ï¼Œé¿å…APIé™æµï¼‰
        
        è¿”å›ï¼š
        {
            'change_3d': 5.2,  # 3å¤©æ¶¨è·Œå¹…%
            'avg_change': 1.7,  # æ—¥å‡æ¶¨è·Œå¹…%
            'rank': 5,  # è¡Œä¸šæ’å
            'total_industries': 30  # æ€»è¡Œä¸šæ•°
        }
        """
        try:
            # ä½¿ç”¨ç¼“å­˜
            cache_key = f"{industry}_{days}"
            if cache_key in self._sector_cache:
                return self._sector_cache[cache_key]
            
            # å¦‚æœå…¨å±€è¡Œä¸šè¡¨ç°ç¼“å­˜ä¸å­˜åœ¨ï¼Œå…ˆè®¡ç®—æ‰€æœ‰è¡Œä¸š
            if self._industry_performance_cache is None:
                self._calculate_all_industries_performance(days)
            
            # ä»ç¼“å­˜ä¸­è·å–è¯¥è¡Œä¸šçš„è¡¨ç°
            if industry in self._industry_performance_cache:
                result = self._industry_performance_cache[industry]
                self._sector_cache[cache_key] = result
                return result
            else:
                # è¡Œä¸šä¸å­˜åœ¨ï¼Œè¿”å›é»˜è®¤å€¼
                return {
                    'change_3d': 0,
                    'avg_change': 0,
                    'rank': 50,
                    'total_industries': len(self._industry_performance_cache) if self._industry_performance_cache else 100,
                    'money_flow': 0
                }
                
        except Exception as e:
            logger.warning(f"è·å–æ¿å—è¡¨ç°å¤±è´¥: {e}")
            return {
                'change_3d': 0,
                'avg_change': 0,
                'rank': 50,
                'total_industries': 100,
                'money_flow': 0
            }
    
    def _calculate_all_industries_performance(self, days: int = 3):
        """
        ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰è¡Œä¸šçš„è¡¨ç°ï¼ˆä½¿ç”¨æœ¬åœ°æ•°æ®åº“ï¼‰
        é¿å…å¯¹æ¯åªè‚¡ç¥¨éƒ½è°ƒç”¨API
        """
        try:
            conn = sqlite3.connect(PERMANENT_DB_PATH)
            
            # è·å–æœ€è¿‘Nå¤©çš„æ—¥æœŸ
            latest_date_query = """
                SELECT MAX(trade_date) as latest_date
                FROM daily_trading_data
            """
            latest_df = pd.read_sql_query(latest_date_query, conn)
            latest_date = latest_df['latest_date'].iloc[0]
            
            # è®¡ç®—èµ·å§‹æ—¥æœŸï¼ˆæœ€è¿‘Nä¸ªäº¤æ˜“æ—¥ï¼‰
            date_query = """
                SELECT DISTINCT trade_date
                FROM daily_trading_data
                WHERE trade_date <= ?
                ORDER BY trade_date DESC
                LIMIT ?
            """
            dates_df = pd.read_sql_query(date_query, conn, params=(latest_date, days+1))
            
            if len(dates_df) < days:
                logger.warning(f"æ•°æ®ä¸è¶³ï¼Œåªæœ‰{len(dates_df)}ä¸ªäº¤æ˜“æ—¥")
                conn.close()
                self._industry_performance_cache = {}
                return
            
            start_date = dates_df['trade_date'].iloc[-1]
            
            # æŸ¥è¯¢æ‰€æœ‰è‚¡ç¥¨åœ¨è¿™æ®µæ—¶é—´çš„æ¶¨è·Œå¹…
            query = """
                SELECT 
                    sb.industry,
                    sb.ts_code,
                    SUM(dt.pct_chg) as total_change
                FROM stock_basic sb
                INNER JOIN daily_trading_data dt ON sb.ts_code = dt.ts_code
                WHERE dt.trade_date >= ?
                AND dt.trade_date <= ?
                AND sb.industry IS NOT NULL
                AND sb.industry != ''
                GROUP BY sb.industry, sb.ts_code
            """
            
            df = pd.read_sql_query(query, conn, params=(start_date, latest_date))
            conn.close()
            
            if len(df) == 0:
                logger.warning("æ²¡æœ‰æŸ¥è¯¢åˆ°è¡Œä¸šæ•°æ®")
                self._industry_performance_cache = {}
                return
            
            # æŒ‰è¡Œä¸šåˆ†ç»„ï¼Œè®¡ç®—å¹³å‡æ¶¨è·Œå¹…
            industry_performance = df.groupby('industry')['total_change'].agg(['mean', 'count']).reset_index()
            industry_performance.columns = ['industry', 'change', 'stock_count']
            
            # è¿‡æ»¤æ‰è‚¡ç¥¨æ•°é‡å¤ªå°‘çš„è¡Œä¸šï¼ˆ<5åªï¼‰
            industry_performance = industry_performance[industry_performance['stock_count'] >= 5]
            
            # æŒ‰æ¶¨è·Œå¹…æ’åºï¼Œè®¡ç®—æ’å
            industry_performance = industry_performance.sort_values('change', ascending=False).reset_index(drop=True)
            industry_performance['rank'] = range(1, len(industry_performance) + 1)
            
            # è½¬æ¢ä¸ºå­—å…¸ç¼“å­˜
            self._industry_performance_cache = {}
            total_industries = len(industry_performance)
            
            for _, row in industry_performance.iterrows():
                self._industry_performance_cache[row['industry']] = {
                    'change_3d': round(row['change'], 2),
                    'avg_change': round(row['change'] / days, 2),
                    'rank': int(row['rank']),
                    'total_industries': total_industries,
                    'money_flow': 0,
                    'stock_count': int(row['stock_count'])
                }
            
            logger.info(f"âœ… æˆåŠŸè®¡ç®—{total_industries}ä¸ªè¡Œä¸šçš„è¡¨ç°")
            
        except Exception as e:
            logger.error(f"è®¡ç®—è¡Œä¸šè¡¨ç°å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            self._industry_performance_cache = {}
    
    def get_money_flow(self, ts_code: str, days: int = 3) -> Dict:
        """
        è·å–èµ„é‡‘æµå‘æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼šAPIå¤±è´¥æ—¶ä½¿ç”¨æœ¬åœ°ä¼°ç®—ï¼‰
        
        è¿”å›ï¼š
        {
            'buy_lg_amount': 5000.0,  # å¤§å•ä¹°å…¥é‡‘é¢ï¼ˆä¸‡å…ƒï¼‰
            'sell_lg_amount': 3000.0,  # å¤§å•å–å‡ºé‡‘é¢ï¼ˆä¸‡å…ƒï¼‰
            'net_mf_amount': 2000.0,  # å‡€æµå…¥ï¼ˆä¸‡å…ƒï¼‰
            'buy_elg_amount': 8000.0,  # è¶…å¤§å•ä¹°å…¥
            'consecutive_inflow_days': 3  # è¿ç»­æµå…¥å¤©æ•°
        }
        """
        try:
            # ä½¿ç”¨ç¼“å­˜
            cache_key = f"{ts_code}_{days}"
            if cache_key in self._money_flow_cache:
                return self._money_flow_cache[cache_key]
            
            # è·å–èµ„é‡‘æµå‘æ•°æ®
            end_date = datetime.now().strftime('%Y%m%d')
            start_date = (datetime.now() - timedelta(days=days+10)).strftime('%Y%m%d')
            
            try:
                # Tushare Proé«˜çº§æ¥å£ï¼šä¸ªè‚¡èµ„é‡‘æµå‘
                money_flow = self.pro.moneyflow(
                    ts_code=ts_code,
                    start_date=start_date,
                    end_date=end_date,
                    fields='trade_date,buy_lg_amount,sell_lg_amount,buy_elg_amount,sell_elg_amount,net_mf_amount'
                )
                
                if len(money_flow) == 0:
                    # APIè¿”å›ç©ºæ•°æ®ï¼Œä½¿ç”¨æœ¬åœ°é™çº§
                    logger.debug(f"{ts_code} APIè¿”å›ç©ºï¼Œä½¿ç”¨æœ¬åœ°ä¼°ç®—")
                    return self._get_money_flow_from_local(ts_code, days)
                
                # æŒ‰æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
                money_flow = money_flow.sort_values('trade_date', ascending=False)
                
                # è®¡ç®—æœ€è¿‘Nå¤©çš„æ•°æ®
                recent = money_flow.head(days)
                
                # å¤§å•å‡€æµå…¥
                buy_lg = recent['buy_lg_amount'].sum() if 'buy_lg_amount' in recent.columns else 0
                sell_lg = recent['sell_lg_amount'].sum() if 'sell_lg_amount' in recent.columns else 0
                
                # è¶…å¤§å•
                buy_elg = recent['buy_elg_amount'].sum() if 'buy_elg_amount' in recent.columns else 0
                sell_elg = recent['sell_elg_amount'].sum() if 'sell_elg_amount' in recent.columns else 0
                
                # å‡€æµå…¥
                net_mf = recent['net_mf_amount'].sum() if 'net_mf_amount' in recent.columns else (buy_lg - sell_lg)
                
                # è¿ç»­æµå…¥å¤©æ•°
                consecutive_days = 0
                for _, row in recent.iterrows():
                    if row.get('net_mf_amount', 0) > 0:
                        consecutive_days += 1
                    else:
                        break
                
                result = {
                    'buy_lg_amount': buy_lg,
                    'sell_lg_amount': sell_lg,
                    'net_mf_amount': net_mf,
                    'buy_elg_amount': buy_elg,
                    'sell_elg_amount': sell_elg,
                    'consecutive_inflow_days': consecutive_days,
                    'today_net': money_flow['net_mf_amount'].iloc[0] if len(money_flow) > 0 else 0
                }
                
                # ç¼“å­˜
                self._money_flow_cache[cache_key] = result
                return result
                
            except Exception as e:
                # APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°é™çº§æ–¹æ¡ˆ
                logger.warning(f"{ts_code} APIå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°ä¼°ç®—: {e}")
                return self._get_money_flow_from_local(ts_code, days)
                
        except Exception as e:
            logger.warning(f"è·å–èµ„é‡‘æµå¤±è´¥: {e}")
            return self._get_money_flow_from_local(ts_code, days)
    
    def _get_money_flow_from_local(self, ts_code: str, days: int = 3) -> Dict:
        """
        ä½¿ç”¨æœ¬åœ°æ•°æ®ä¼°ç®—èµ„é‡‘æµå‘ï¼ˆé™çº§æ–¹æ¡ˆï¼‰
        
        åŸç†ï¼šæ¶¨å¹… Ã— æ”¾é‡æ¯”ä¾‹ = èµ„é‡‘æµå‘ä¼°ç®—
        """
        try:
            conn = sqlite3.connect(PERMANENT_DB_PATH)
            
            # æŸ¥è¯¢æœ€è¿‘Nå¤©çš„æ•°æ®
            query = """
                SELECT 
                    vol,
                    pct_chg,
                    close_price,
                    trade_date
                FROM daily_trading_data
                WHERE ts_code = ?
                ORDER BY trade_date DESC
                LIMIT ?
            """
            df = pd.read_sql_query(query, conn, params=(ts_code, days + 20))
            conn.close()
            
            if len(df) < days:
                return self._default_money_flow()
            
            # è®¡ç®—å¹³å‡æˆäº¤é‡ï¼ˆç”¨äºåˆ¤æ–­æ”¾é‡ï¼‰
            avg_vol = df['vol'].iloc[days:].mean() if len(df) > days else df['vol'].mean()
            
            if avg_vol == 0:
                return self._default_money_flow()
            
            # è®¡ç®—èµ„é‡‘æµå‘
            net_flow = 0
            consecutive_days = 0
            recent_data = df.head(days)
            
            for i, row in recent_data.iterrows():
                vol_ratio = row['vol'] / avg_vol
                price_chg = row['pct_chg']
                
                # ä¼°ç®—èµ„é‡‘æµï¼šæ¶¨å¹… Ã— (æ”¾é‡æ¯”ä¾‹-1) Ã— åŸºæ•°
                # ğŸ”¥ å¤§å¹…æé«˜ä¼°ç®—ç³»æ•°ï¼šä»500æé«˜åˆ°8000ï¼ˆæ›´æ¥è¿‘çœŸå®èµ„é‡‘æµè§„æ¨¡ï¼‰
                if price_chg > 0 and vol_ratio > 1.0:
                    day_flow = price_chg * (vol_ratio - 1) * 8000  # ä¼°ç®—ä¸‡å…ƒ
                    net_flow += day_flow
                    consecutive_days += 1
                elif price_chg < 0 and vol_ratio > 1.0:
                    day_flow = price_chg * (vol_ratio - 1) * 8000
                    net_flow += day_flow
                    break  # è·Œåœæ­¢è®¡ç®—è¿ç»­å¤©æ•°
                else:
                    break
            
            return {
                'net_mf_amount': round(net_flow, 2),
                'consecutive_inflow_days': consecutive_days,
                'buy_lg_amount': max(0, net_flow),
                'sell_lg_amount': max(0, -net_flow),
                'buy_elg_amount': 0,
                'sell_elg_amount': 0,
                'today_net': 0
            }
            
        except Exception as e:
            logger.warning(f"æœ¬åœ°èµ„é‡‘æµè®¡ç®—å¤±è´¥ {ts_code}: {e}")
            return self._default_money_flow()
    
    def _load_hs_const_stocks(self):
        """ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰é™†è‚¡é€šæ ‡çš„ï¼ˆé¿å…é‡å¤è°ƒç”¨APIï¼‰"""
        if self._hs_const_stocks is not None:
            return  # å·²åŠ è½½
        
        try:
            logger.info("æ­£åœ¨åŠ è½½é™†è‚¡é€šæ ‡çš„...")
            # ä»Tushareè·å–é™†è‚¡é€šæˆåˆ†è‚¡ï¼ˆåªè°ƒç”¨2æ¬¡ï¼‰
            sh_const = self.pro.hs_const(hs_type='SH')  # æ²ªè‚¡é€š
            sz_const = self.pro.hs_const(hs_type='SZ')  # æ·±è‚¡é€š
            
            all_const = pd.concat([sh_const, sz_const])
            self._hs_const_stocks = set(all_const['ts_code'].tolist())
            
            logger.info(f"âœ… æˆåŠŸåŠ è½½{len(self._hs_const_stocks)}åªé™†è‚¡é€šæ ‡çš„")
            
        except Exception as e:
            logger.warning(f"åŠ è½½é™†è‚¡é€šæ ‡çš„å¤±è´¥: {e}")
            self._hs_const_stocks = set()
    
    def get_north_money_flow(self, ts_code: str, days: int = 3) -> Dict:
        """
        è·å–åŒ—å‘èµ„é‡‘ï¼ˆé™†è‚¡é€šï¼‰æµå‘ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        
        è¿”å›ï¼š
        {
            'buy_amount': 0,  # ä¹°å…¥é‡‘é¢ï¼ˆç®€åŒ–ç‰ˆä¸æä¾›ï¼‰
            'sell_amount': 0,  # å–å‡ºé‡‘é¢ï¼ˆç®€åŒ–ç‰ˆä¸æä¾›ï¼‰
            'net_amount': 0,  # å‡€ä¹°å…¥ï¼ˆç®€åŒ–ç‰ˆä¸æä¾›ï¼‰
            'consecutive_buy_days': 0,  # è¿ç»­ä¹°å…¥å¤©æ•°ï¼ˆç®€åŒ–ç‰ˆä¸æä¾›ï¼‰
            'is_connect_stock': True  # æ˜¯å¦é™†è‚¡é€šæ ‡çš„ï¼ˆå‡†ç¡®åˆ¤æ–­ï¼‰
        }
        """
        try:
            # ä½¿ç”¨ç¼“å­˜
            cache_key = f"{ts_code}_north_{days}"
            if cache_key in self._north_money_cache:
                return self._north_money_cache[cache_key]
            
            # ç¡®ä¿å·²åŠ è½½é™†è‚¡é€šæ ‡çš„
            if self._hs_const_stocks is None:
                self._load_hs_const_stocks()
            
            # åˆ¤æ–­æ˜¯å¦é™†è‚¡é€šæ ‡çš„ï¼ˆä»ç¼“å­˜ï¼‰
            is_connect = ts_code in self._hs_const_stocks if self._hs_const_stocks else False
            
            result = {
                'buy_amount': 0,
                'sell_amount': 0,
                'net_amount': 0,
                'north_net_3d': 0,  # åˆ«åï¼Œå…¼å®¹v6è¯„åˆ†å™¨
                'consecutive_buy_days': 0,
                'is_connect_stock': is_connect
            }
            
            # ç¼“å­˜
            self._north_money_cache[cache_key] = result
            return result
                
        except Exception as e:
            logger.warning(f"è·å–åŒ—å‘èµ„é‡‘å¤±è´¥: {e}")
            return {
                'buy_amount': 0,
                'sell_amount': 0,
                'net_amount': 0,
                'north_net_3d': 0,  # åˆ«åï¼Œå…¼å®¹v6è¯„åˆ†å™¨
                'consecutive_buy_days': 0,
                'is_connect_stock': False
            }
    
    def get_market_change(self, days: int = 3) -> float:
        """
        è·å–å¤§ç›˜æ¶¨è·Œå¹…ï¼ˆä»æœ¬åœ°æ•°æ®åº“ï¼‰
        
        è¿”å›ï¼šå¤§ç›˜Nå¤©æ¶¨è·Œå¹…ï¼ˆ%ï¼‰
        """
        try:
            conn = sqlite3.connect(PERMANENT_DB_PATH)
            
            # è·å–ä¸Šè¯æŒ‡æ•°æœ€è¿‘Nå¤©çš„æ¶¨è·Œå¹…
            query = """
                SELECT SUM(pct_chg) as total_change
                FROM (
                    SELECT pct_chg
                    FROM daily_trading_data
                    WHERE ts_code = '000001.SH'
                    ORDER BY trade_date DESC
                    LIMIT ?
                )
            """
            
            df = pd.read_sql_query(query, conn, params=(days,))
            conn.close()
            
            if len(df) > 0 and not pd.isna(df['total_change'].iloc[0]):
                return float(df['total_change'].iloc[0])
            else:
                return 0.0
                
        except Exception as e:
            logger.warning(f"è·å–å¤§ç›˜æ¶¨è·Œå¹…å¤±è´¥: {e}")
            return 0.0
    
    def _default_money_flow(self) -> Dict:
        """é»˜è®¤èµ„é‡‘æµæ•°æ®"""
        return {
            'buy_lg_amount': 0,
            'sell_lg_amount': 0,
            'net_mf_amount': 0,
            'buy_elg_amount': 0,
            'sell_elg_amount': 0,
            'consecutive_inflow_days': 0,
            'today_net': 0
        }
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        self._sector_cache.clear()
        self._money_flow_cache.clear()
        self._north_money_cache.clear()
        self._industry_performance_cache = None


# å…¨å±€å•ä¾‹
_data_provider_optimized = None

def get_data_provider() -> V6DataProviderOptimized:
    """è·å–ä¼˜åŒ–ç‰ˆæ•°æ®æä¾›è€…å•ä¾‹"""
    global _data_provider_optimized
    if _data_provider_optimized is None:
        _data_provider_optimized = V6DataProviderOptimized()
    return _data_provider_optimized

